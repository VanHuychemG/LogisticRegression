{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht classificatie 1 - logistic regression\n",
    "\n",
    "Logistische regressie is een bijzonder populaire classificatietechniek. Enerzijds door zijn eenvoud en relatief lage eisen die het stelt in termen van rekenkracht. In veel gevallen is de performantie qua accuracy vergelijkbaar (en soms beter) dan gecompliceerdere algoritmes zoals de support vector machines.\n",
    "Daarnaast heeft logistische regressie het voordeel dat het getrainde model een voorspelling doet in termen van de kans dat de input tot een bepaalde klasse behoort. Uit deze kans kan je afleiden hoe overtuigd het model is van de gemaakte voorspelling.\n",
    "\n",
    "Het is de bedoeling om via enkele classificatieopdrachten inzicht te verkrijgen in:\n",
    "- Correct trainen en het uitvoeren van hyperparameter tuning bij logistische regressie.\n",
    "- Classificaties kunnen uitvoeren via logistische regressie.\n",
    "- Feature engineering uitvoeren.\n",
    "- Weten wanneer je te maken hebt met overfitting en underfitting en de juiste bijstellingen kunnen doen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 1: Classificatie van wijn\n",
    "\n",
    "Het doel van deze classificatie is te kunnen achterhalen op basis van chemische parameters van welke wijnboer (cultivar) een wijn afkomstig is.\n",
    "\n",
    "Gebruik hiervoor de dataset *wine_data.csv*. De features bevinden zich in de eerste kolommen van de dataset. De targets/outputs zijn in de laatste kolom te vinden.\n",
    "\n",
    "### Inlezen van de dataset en vooranalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs Alcohol</th>\n",
       "      <th>MalicAcid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>AlcalinityOfAsh</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>TotalPhenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>NonflavanoidsPhenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>ColorIntensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Cultivar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2.30</td>\n",
       "      <td>23.6</td>\n",
       "      <td>70</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.07</td>\n",
       "      <td>3.21</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.51</td>\n",
       "      <td>24.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.72</td>\n",
       "      <td>630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.92</td>\n",
       "      <td>19.6</td>\n",
       "      <td>78</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.68</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.48</td>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.11</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.70</td>\n",
       "      <td>15.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.28</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.18</td>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.04</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.38</td>\n",
       "      <td>22.0</td>\n",
       "      <td>80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.57</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.25</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.69</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.7</td>\n",
       "      <td>80</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.06</td>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.77</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.98</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.12</td>\n",
       "      <td>372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.88</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.23</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.33</td>\n",
       "      <td>415</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.32</td>\n",
       "      <td>18.5</td>\n",
       "      <td>81</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.27</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inputs Alcohol  MalicAcid   Ash  AlcalinityOfAsh  Magnesium  TotalPhenols  \\\n",
       "0           12.08       1.33  2.30             23.6         70          2.20   \n",
       "1           12.08       1.13  2.51             24.0         78          2.00   \n",
       "2           12.37       1.17  1.92             19.6         78          2.11   \n",
       "3           13.11       1.01  1.70             15.0         78          2.98   \n",
       "4           12.04       4.30  2.38             22.0         80          2.10   \n",
       "5           12.25       1.73  2.12             19.0         80          1.65   \n",
       "6           12.69       1.53  2.26             20.7         80          1.38   \n",
       "7           12.77       3.43  1.98             16.0         80          1.63   \n",
       "8           13.88       5.04  2.23             20.0         80          0.98   \n",
       "9           12.08       1.83  2.32             18.5         81          1.60   \n",
       "\n",
       "   flavanoids  NonflavanoidsPhenols  Proanthocyanins  ColorIntensity   Hue  \\\n",
       "0        1.59                  0.42             1.38            1.74  1.07   \n",
       "1        1.58                  0.40             1.40            2.20  1.31   \n",
       "2        2.00                  0.27             1.04            4.68  1.12   \n",
       "3        3.18                  0.26             2.28            5.30  1.12   \n",
       "4        1.75                  0.42             1.35            2.60  0.79   \n",
       "5        2.03                  0.37             1.63            3.40  1.00   \n",
       "6        1.46                  0.58             1.62            3.05  0.96   \n",
       "7        1.25                  0.43             0.83            3.40  0.70   \n",
       "8        0.34                  0.40             0.68            4.90  0.58   \n",
       "9        1.50                  0.52             1.64            2.40  1.08   \n",
       "\n",
       "   OD280/OD315  Proline  Cultivar  \n",
       "0         3.21      625         1  \n",
       "1         2.72      630         1  \n",
       "2         3.48      510         1  \n",
       "3         3.18      502         1  \n",
       "4         2.57      580         1  \n",
       "5         3.17      510         1  \n",
       "6         2.06      495         1  \n",
       "7         2.12      372         1  \n",
       "8         1.33      415         2  \n",
       "9         2.27      480         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inlezen van de data\n",
    "dataset = pd.read_csv('wine_data.csv')\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal het aantal klasses. Met andere woorden, hoeveel verschillende wijnboeren zijn er?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    71\n",
      "0    59\n",
      "2    48\n",
      "Name: Cultivar, dtype: int64\n",
      "\n",
      "Het aantal klasses (of wijnboeren) bedraagt  3\n"
     ]
    }
   ],
   "source": [
    "print(pd.value_counts(dataset['Cultivar']))\n",
    "print()\n",
    "print('Het aantal klasses (of wijnboeren) bedraagt ', len(dataset['Cultivar'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoeveel wijnen van elke wijnboer steken in de dataset? Is de dataset gebalanceerd? Gebalanceerd wil zeggen dat elke klasse ongeveer even sterk in de dataset aanwezig is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wijnboer  0  ==>  59  wijnen\n",
      "Wijnboer  1  ==>  71  wijnen\n",
      "Wijnboer  2  ==>  48  wijnen\n"
     ]
    }
   ],
   "source": [
    "dict = dataset.groupby(['Cultivar']).groups\n",
    "\n",
    "for key, value in dict.items():\n",
    "    print('Wijnboer ', key, ' ==> ', len(value), ' wijnen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal de statistische kerngetallen van de verschillende features en targets. Gebruik hiervoor de *describe* functie (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html). Gebruik de resultaten om na te gaan of er mogelijks ontbrekende waarden, uitschieters of onrealistische waarden zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs Alcohol</th>\n",
       "      <th>MalicAcid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>AlcalinityOfAsh</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>TotalPhenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>NonflavanoidsPhenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>ColorIntensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Cultivar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>0.938202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>0.775035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       inputs Alcohol   MalicAcid         Ash  AlcalinityOfAsh   Magnesium  \\\n",
       "count      178.000000  178.000000  178.000000       178.000000  178.000000   \n",
       "mean        13.000618    2.336348    2.366517        19.494944   99.741573   \n",
       "std          0.811827    1.117146    0.274344         3.339564   14.282484   \n",
       "min         11.030000    0.740000    1.360000        10.600000   70.000000   \n",
       "25%         12.362500    1.602500    2.210000        17.200000   88.000000   \n",
       "50%         13.050000    1.865000    2.360000        19.500000   98.000000   \n",
       "75%         13.677500    3.082500    2.557500        21.500000  107.000000   \n",
       "max         14.830000    5.800000    3.230000        30.000000  162.000000   \n",
       "\n",
       "       TotalPhenols  flavanoids  NonflavanoidsPhenols  Proanthocyanins  \\\n",
       "count    178.000000  178.000000            178.000000       178.000000   \n",
       "mean       2.295112    2.029270              0.361854         1.590899   \n",
       "std        0.625851    0.998859              0.124453         0.572359   \n",
       "min        0.980000    0.340000              0.130000         0.410000   \n",
       "25%        1.742500    1.205000              0.270000         1.250000   \n",
       "50%        2.355000    2.135000              0.340000         1.555000   \n",
       "75%        2.800000    2.875000              0.437500         1.950000   \n",
       "max        3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       ColorIntensity         Hue  OD280/OD315      Proline    Cultivar  \n",
       "count      178.000000  178.000000   178.000000   178.000000  178.000000  \n",
       "mean         5.058090    0.957449     2.611685   746.893258    0.938202  \n",
       "std          2.318286    0.228572     0.709990   314.907474    0.775035  \n",
       "min          1.280000    0.480000     1.270000   278.000000    0.000000  \n",
       "25%          3.220000    0.782500     1.937500   500.500000    0.000000  \n",
       "50%          4.690000    0.965000     2.780000   673.500000    1.000000  \n",
       "75%          6.200000    1.120000     3.170000   985.000000    2.000000  \n",
       "max         13.000000    1.710000     4.000000  1680.000000    2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs Alcohol          False\n",
       "MalicAcid               False\n",
       "Ash                     False\n",
       "AlcalinityOfAsh         False\n",
       "Magnesium               False\n",
       "TotalPhenols            False\n",
       "flavanoids              False\n",
       "NonflavanoidsPhenols    False\n",
       "Proanthocyanins         False\n",
       "ColorIntensity          False\n",
       "Hue                     False\n",
       "OD280/OD315             False\n",
       "Proline                 False\n",
       "Cultivar                False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records with outliers:  10\n"
     ]
    }
   ],
   "source": [
    "#search for outliers\n",
    "from scipy import stats\n",
    "z = np.abs(stats.zscore(dataset))\n",
    "threshold = 3\n",
    "\n",
    "outliers = len(dataset) - len(dataset[dataset.sub(dataset.mean()).div(dataset.std()).abs() <= threshold].dropna())\n",
    "print(\"records with outliers: \", outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[(np.abs(stats.zscore(dataset)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing en opsplitsen van de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits de dataset in **features en targets**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(dataset.columns[:dataset.columns.size-1])\n",
    "X = dataset[features].values \n",
    "y= dataset['Cultivar'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normaliseer de dataset**. Zorg er dus voor dat de features op een gelijke schaalverdeling staan. Voor het normaliseren kan gebruik gemaakt worden van de *preprocessing.StandardScaler()*. Meer info over het gebruik ervan is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creëer een **trainingset en een testset**. Zorg dat je 70 wijnen in de test set zitten hebt. Gebruik hiervoor train_test_split functie. Meer info is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=70, random_state=0)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_std = scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen van een logistic regression classifier en testen van het bekomen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train een logistic regression classifier (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) op de training data. \n",
    "Kies C=1 als startwaarde. \n",
    "\n",
    "Test het getrainde model op de test set. Bepaal hierbij de confusion matrix, de accuracy en het classification report. Wat zijn de bevindingen?\n",
    "\n",
    "Probeer indien nodig de performantie van de classifier te verhogen door de parameter C  aan te passen, class_weight aan te passen of een andere solver toe te passen. \n",
    "Schrijf de conclusies neer. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 0.1\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "# finetunen van model\n",
    "param_grid = [{'C': np.logspace(-3,3,7), 'penalty': ['l1','l2'] }]\n",
    "\n",
    "gs = GridSearchCV(estimator=logreg, param_grid=param_grid, scoring='accuracy', cv=10)\n",
    "gs = gs.fit(X_train_std, y_train)\n",
    "\n",
    "print('Best Penalty:', gs.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', gs.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg = linear_model.LogisticRegression(C=0.1, random_state=0, penalty='l1')\n",
    "\n",
    "#class_weight : dict or ‘balanced’, default: None\n",
    "#Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one.\n",
    "#The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).\n",
    "#Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.\n",
    "\n",
    "#solver : str, {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default: ‘liblinear’.\n",
    "#Algorithm to use in the optimization problem.\n",
    "#- For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "#- For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "#- ‘newton-cg’, ‘lbfgs’ and ‘sag’ only handle L2 penalty, whereas ‘liblinear’ and ‘saga’ handle L1 penalty.\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=0.1, random_state=0, penalty='l2', class_weight= 'balanced', solver= 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=0,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[25  0  0]\n",
      " [ 0 27  2]\n",
      " [ 0  0 16]]\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score\n",
      "0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score')\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       1.00      0.93      0.96        29\n",
      "           2       0.89      1.00      0.94        16\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        70\n",
      "   macro avg       0.96      0.98      0.97        70\n",
      "weighted avg       0.97      0.97      0.97        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voorspel aan de hand van het getrainde model\n",
    "\n",
    "Voorspel van welke wijnboer een wijn afkomstig is met volgende samenstelling:\n",
    "\n",
    "inputs Alcohol: 13.52 - \n",
    "MalicAcid: 2.05 - \n",
    "Ash: 2.20 - \n",
    "AlcalinityOfAsh: 17.3 - \n",
    "Magnesium: 120 - \n",
    "TotalPhenols: 2.60 - \n",
    "flavanoids: 3.52 - \n",
    "NonflavanoidsPhenols: 0.30 - \n",
    "Proanthocyanins: 2.28 - \n",
    "ColorIntensity: 7.80 - \n",
    "Hue: 0.77 - \n",
    "OD280/OD315: 2.90 - \n",
    "Proline: 862\n",
    "\n",
    "\n",
    "Geef ook de overtuiging van het model weer dat de wijn van die bepaalde wijnboer afkomstig is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wijnboer:  [0]\n",
      "Wijnboer 0/1/2 [[1.00000000e+000 2.15710883e-264 3.94440391e-015]]\n"
     ]
    }
   ],
   "source": [
    "print('Wijnboer: ', logreg.predict(np.array([13.52,2.05,2.20,17.3,120,2.60,3.52,0.30,2.28,7.80,0.77,2.90,862]).reshape(1,-1)))\n",
    "\n",
    "print('Wijnboer 0/1/2', logreg.predict_proba(np.array([13.52,2.05,2.20,17.3,120,2.60,3.52,0.30,2.28,7.80,0.77,2.90,862]).reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 2: Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het bestand *diabetes.csv* bevat medische gegevens van meer dan 300 personen waarbij telkens geweten is of de persoon al dan niet diabetes heeft.\n",
    "Train nu een logic regression model dat op basis van de features een zo goed mogelijke predictie kan doen of iemand al dan niet diabetes heeft.\n",
    "\n",
    "### Inlezen van de dataset en vooranalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "5            5      116             74              0        0  25.6   \n",
       "6            3       78             50             32       88  31.0   \n",
       "7           10      115              0              0        0  35.3   \n",
       "8            2      197             70             45      543  30.5   \n",
       "9            8      125             96              0        0   0.0   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  \n",
       "5                     0.201   30        0  \n",
       "6                     0.248   26        1  \n",
       "7                     0.134   29        0  \n",
       "8                     0.158   53        1  \n",
       "9                     0.232   54        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inlezen van de dataset\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controleer of de dataset inconsistenties of foute waarden bevat. Gebruik listwise deletion. Dit betekent dat je alle gegevens van een persoon uit de dataset verwijdert van zodra er 1 feature foutief is of ontbreekt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal de verdeling van het aantal personen met diabetes ten opzichte van het aantal personen zonder. Is de dataset gebalanceerd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal de statistische kerngetallen van de verschillende features en target. Gebruik hiervoor de *describe* functie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing en opsplitsen van de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits de dataset in **features en targets**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normaliseer de dataset**. Zorg er dus voor dat de features op een gelijke schaalverdeling staan. Voor het normaliseren kan gebruik gemaakt worden van de *preprocessing.StandardScaler()*. Meer info over het gebruik ervan is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creëer een **trainingset en een testset**. Zorg dat er 100 patiënten in de testset steken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen van een logistic regression classifier en testen van het bekomen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train een logistic regression classifier op de training data. Kies C=1 als startwaarde. Mocht de dataset niet gebalanceerd zijn (de ene klasse komt frequenter voor dan de andere klasse) dan kan je bij de creatie van het logistic regression model de parameter class_weight='balanced' meegeven. Meer info: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "Test het getrainde model op de test set. Bepaal hierbij de confusion matrix, de accuracy en het classification report. Wat zijn de bevindingen? Probeer ook verschillende solvers uit.\n",
    "\n",
    "Probeer de performantie van de classifier te verhogen door de parameter C te veranderen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "Creeër hogere orde features door gebruik te maken van *preprocessing.PolynomialFeatures*. Meer info is te vinden op http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "\n",
    "Deze functie zal automatische hogere orde features aanmaken door het combineren van de aanwezige features. Heb je bijvoorbeeld drie features, zijnde A, B en C dan worden bij de keuze van een derde orde PolynomialFeatures volgende nieuwe features bijgemaakt:\n",
    "$A^3, B^3,C^3,A^2B,A^2C,AB^2, B^2C,...$\n",
    "\n",
    "Experimenteer met verschillende ordes en gebruik de regularisatieparameter C om de performantie te verhogen.\n",
    "\n",
    "**Opgepast**: het kiezen van een te hoge orde zorgt voor een exponentiële toename aan features waardoor de logistic regression classifier niet meer binnen aanvaardbare tijd getraind kan worden. Advies is om niet hoger te gaan dan 4de orde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat zijn de bevindingen? Formuleer een conclusie. Bespreek hierin de performantie van de getrainde modellen. Wat is de invloed van de parameter C en van het aantal features? Heb je te maken gehad met underfitting en overfitting en hoe heb je dit bepaald? Welke accuracy werd bekomen en hoe zit het met de Recall en Precision? Is de grootte van de trainingset voldoende?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voorspel aan de hand van het getrainde model\n",
    "\n",
    "Voorspel of iemand met onderstaande medische parameters als dan niet diabetes heeft. Geef ook de zekerheid van het model weer (kansen dat de patiënt tot een bepaalde klasse behoort).\n",
    "\n",
    "Pregnancies: 2 -\n",
    "Glucose: 132 -\n",
    "BloodPressure: 74 - \n",
    "SkinThickness: 20 - \n",
    "Insulin: 21 - \n",
    "BMI: 24.3 - \n",
    "DiabetesPedigreeFunction: 128 - \n",
    "Age: 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opdracht 3: Kankerdetectie\n",
    "\n",
    "Train een model om te voorspellen of een bepaalde tumor goedaardig (benign) of kwaadaardig (malignant) is.\n",
    "Gebruik daarvoor de dataset '*cancer.csv*'\n",
    "\n",
    "Baseer je op de methodieken uit voorgaande opdrachten om tot een zo goed mogelijk resultaat te komen. \n",
    "**Bespreek** telkens de gemaakte keuzes en resultaten en kom tot een duidelijk besluit.\n",
    "\n",
    "Tip: een classifier kan enkel maar getraind worden met numerieke waarden. Vervang daarom bij de feature diagnose de twee klasses die voorkomen door 0 en 1, waarbij 0 staat voor goedaardig en 1 voor kwaadaardig.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voorspel of een gezwel met onderstaande parameters goedaardig of kwaadaardig is.\n",
    "\n",
    "radius_mean: 17.99 |\n",
    "texture_mean: 10.38 |\n",
    "perimeter_mean: 122.8 |\n",
    "area_mean: 1001 |\n",
    "smoothness_mean: 0.1184 |\n",
    "compactness_mean: 0.2776 |\n",
    "concavity_mean: 0.3001 |\n",
    "concave points_mean: 0.1471 |\n",
    "symmetry_mean: 0.2419 |\n",
    "fractal_dimension_mean: 0.07871 |\n",
    "radius_se: 1.095 |\n",
    "texture_se: 0.9053 |\n",
    "perimeter_se: 8.589 |\n",
    "area_se:153.4 |\n",
    "smoothness_se:0.006399 |\n",
    "compactness_se: 0.04904 |\n",
    "concavity_se: 0.05373 |\n",
    "concave points_se: 0.01587 |\n",
    "symmetry_se: 0.03003 |\n",
    "fractal_dimension_se: 0.006193 |\n",
    "radius_worst: 25.38 |\n",
    "texture_worst: 17.33 |\n",
    "perimeter_worst: 184.6 |\n",
    "area_worst: 2019 |\n",
    "smoothness_worst: 0.1622 |\n",
    "compactness_worst: 0.6656 |\n",
    "concavity_worst: 0.7119 |\n",
    "concave points_worst: 0.2654 |\n",
    "symmetry_worst: 0.4601 |\n",
    "fractal_dimension_worst: 0.1189 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
